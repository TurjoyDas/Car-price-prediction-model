

#importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn import neighbors
from math import sqrt
from sklearn.tree import export_graphviz
import graphviz
from IPython.display import display

from google.colab import drive
drive.mount('/content/drive')

df=pd.read_csv('/content/drive/MyDrive/422Project_cardekho/cardekho.csv')

df.head()

df.tail()

df.describe()

"""### **CHANGING DATATYPE:**"""

df['max_power'] = df['max_power'].replace(' ', np.nan)
df['max_power'] = df['max_power'].astype(float)

"""### **Checking Categorical and Quantive Features:**"""

unique_counts = df.nunique()

categorical_features = unique_counts[unique_counts <= 10].index
quantitative_features = unique_counts[unique_counts > 10].index

nc = len(categorical_features)
qc = len(quantitative_features)

print(f"Categorical Features: {nc}")
print(categorical_features)

print(f"\nQuantitative Features: {qc}")
print(quantitative_features)

df.info()

"""### **Droping Object type Column for visualizing Correlation :**

---


"""

cdf=df.copy()
drp=['name','fuel','seller_type','transmission','owner']
cdf.drop(drp,axis=1,inplace=True)

cdf.corr()

correlation = cdf.corr()
plt.figure(figsize=(16,10))
ax = sns.heatmap(correlation, square=True, annot=True, fmt='.2f', linecolor='white')
ax.set_xticklabels(ax.get_xticklabels(), rotation=90)
ax.set_yticklabels(ax.get_yticklabels(), rotation=30)
plt.show()

"""### **Distribution of Features :**"""

categorical_cols = cdf.columns.tolist()
for feature in categorical_cols:
    plt.figure(figsize=(17, 5))
    sns.histplot(cdf[feature], bins=20, kde=True)

    plt.title(f"Overall distribution of {feature}")
    plt.xticks(rotation=85)
    plt.show()

"""### **Preprocessing Starts:**"""

df.isnull()

df.isnull().sum()

"""### **Imputing using Mean, Median or Mode:**"""

from sklearn.impute import SimpleImputer

impute = SimpleImputer(missing_values=np.nan, strategy='mean')
df['mileage(km/ltr/kg)'] = impute.fit_transform(df[['mileage(km/ltr/kg)']])


impute = SimpleImputer(missing_values=np.nan, strategy='mean')
df['engine'] = impute.fit_transform(df[['engine']])


impute = SimpleImputer(missing_values=np.nan, strategy='mean')
df['max_power'] = impute.fit_transform(df[['max_power']])


impute = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
df['seats'] = impute.fit_transform(df[['seats']])

df.isnull().sum()

"""### **Checking Duplicate rows and droping them :**"""

total_duplicates = df.duplicated().sum()
print(f"Total number of duplicate rows: {total_duplicates}")

df.drop_duplicates(inplace = True)

total_duplicates = df.duplicated().sum()
print(f"Total number of duplicate rows: {total_duplicates}")

df.shape

df.head()

df.info()

"""### **Checking Categorical types for Encoding:**"""

num_unique_sellers = df['transmission'].nunique()
print("Number of unique values in 'transmission'' column:", num_unique_sellers)
unique_sellers = df['transmission'].unique()
print("Unique values in 'transmission' column:", unique_sellers)


print("--------------------------------------------------------------------------------------------------------------")

num_unique_sellers = df['seller_type'].nunique()
print("Number of unique values in 'seller_type' column:", num_unique_sellers)
unique_sellers = df['seller_type'].unique()
print("Unique values in 'seller_type' column:", unique_sellers)

print("--------------------------------------------------------------------------------------------------------------")


num_unique_sellers = df['fuel'].nunique()
print("Number of unique values in 'fuel' column:", num_unique_sellers)
unique_sellers = df['fuel'].unique()
print("Unique values in 'fuel' column:", unique_sellers)

print("--------------------------------------------------------------------------------------------------------------")

num_unique_sellers = df['owner'].nunique()
print("Number of unique values in 'owner' column:", num_unique_sellers)
unique_sellers = df['owner'].unique()
print("Unique values in 'owner' column:", unique_sellers)

main=df.copy()

main.head()

"""### **Encoding column values after coping the dataset into Main:**"""

main['transmission'] = main['transmission'].map({'Manual': 1, 'Automatic': 2})
main['seller_type'] = main['seller_type'].map({'Individual': 1, 'Dealer': 2, 'Trustmark Dealer':3})
main['fuel'] = main['fuel'].map({'Diesel': 1, 'Petrol': 2,'LPG':3,'CNG':4})
main['owner'] = main['owner'].map({'First Owner': 1, 'Second Owner': 2,'Third Owner':3,'Fourth & Above Owner':4,'Test Drive Car':5})

main.head()

main.info()

columns_to_drop = ['name']
main.drop(columns_to_drop, axis=1, inplace=True)

main.head()

maini=main.copy()

maini .info()

maini.head()

"""### **Scaling:**"""

scaler = StandardScaler()

batch_size = 500

for i in range(0, len(main), batch_size):
    scaler.partial_fit(main[i:i+batch_size])

X_scaled = scaler.transform(main)

X_scaled

X_scaled.shape

X_scaled_df = pd.DataFrame(X_scaled, columns=main.columns)
numeric_columns = main.select_dtypes(include=['int64', 'float64']).columns
housing_numeric = main[numeric_columns]

corr_before = main.corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr_before, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix (Before Standardization, Encoding and Imputation)')
plt.show()

X_scaled_df = pd.DataFrame(X_scaled, columns=main.columns)

corr_after = X_scaled_df.corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr_after, cmap='GnBu')
plt.title('Correlation Matrix (After Standardization, Encoding and Imputation)')
plt.show()

"""### **Dataset Splitting for Train-test:**"""

X = X_scaled
y = main['selling_price'].to_numpy()

X

y

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

print(" ")

print("Total number of samples:", len(X_scaled))
print("Number of samples in the training set:", len(X_train))
print("Number of samples in the testing set:", len(X_test))
print("Sum of samples in train and test:", len(X_train) + len(X_test))

test_size_example = len(X_test) / len(X_scaled)
print("Test size proportion:", test_size_example)

print('''
Checking if train and test split is successful
''')

print("Difference:", np.abs(test_size_example - 0.3))

"""### **Checking Overlap:**"""

X = pd.DataFrame(X_scaled)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42)

if any(np.intersect1d(X_train.index, X_test.index)):
    print("The train and test data is mixed.")
else:
    print("The train and test data is not mixed.")

"""### **Linear Regression Model:**"""

linreg = LinearRegression().fit(X_train, y_train)
residuals = y_train - linreg.predict(X_train)
outlier_threshold = 3*np.std(residuals)
outliers = np.abs(residuals) > outlier_threshold

linreg_score = 0

if np.all(outliers):
    print("All samples are outliers, cannot fit a linear regression model")
else:
    X_train_cleaned, y_train_cleaned = X_train[~outliers], y_train[~outliers]

    linreg_cleaned = LinearRegression().fit(X_train_cleaned, y_train_cleaned)

    y_pred_cleaned = linreg_cleaned.predict(X_test)

    mse_cleaned = mean_squared_error(y_test, y_pred_cleaned)
    rmse_cleaned = np.sqrt(mse_cleaned)
    mae = mean_absolute_error(y_test, y_pred_cleaned)

    r2_score_cleaned = r2_score(y_test, y_pred_cleaned) * 100

    linreg_score = r2_score_cleaned
    linreg_mae = mae

    print(f"Mean Squared Error: {mse_cleaned:.2f}")
    print(f"Root Mean Squared Error: {rmse_cleaned:.2f}")
    print(f"Mean Absolute Error: {mae:.2f}")
    print(" ")
    print(f"R^2 Score: {r2_score_cleaned:.6f}%")

train_accuracy = linreg_cleaned.score(X_train_cleaned, y_train_cleaned)

test_accuracy = linreg_cleaned.score(X_test, y_test)

print('Training accuracy:', train_accuracy)
print('Test accuracy:', test_accuracy)

plt.scatter(y_test, y_pred_cleaned)
plt.plot([0, 50000], [0, 50000], '--k')
plt.xlabel('Actual values')
plt.ylabel('Predicted values')
plt.title('Actual vs. Predicted SalePrice (Linear Regression Model)')
plt.show()

"""### **Decision Tree Model:**"""

X = X_scaled
y = main['selling_price'].to_numpy()

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42)

decisionTreeRegressor = DecisionTreeRegressor()

decisionTreeRegressor.fit(X_train, y_train)

y_pred = decisionTreeRegressor.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)
mae = mean_absolute_error(y_test, y_pred)

r2 = (decisionTreeRegressor.score(X_test,y_test))*100

dectree_score = r2
dectree_mae = mae

print(f"Mean Squared Error: {mse:.2f}")
print(f"Root Mean Squared Error: {rmse:.2f}")
print(f"Mean Absolute Error: {mae:.2f}")
print(" ")

train_accuracy = decisionTreeRegressor.score(X_train, y_train)
test_accuracy = decisionTreeRegressor.score(X_test, y_test)

print('Training accuracy:', train_accuracy)
print('Test accuracy:', test_accuracy) #as we got 1 as result and it is completely fine because the limit is 5-10%

dot_data = export_graphviz(decisionTreeRegressor, out_file=None,
                           feature_names=list(main.columns),
                           filled=True, rounded=True,
                           special_characters=True)

graph = graphviz.Source(dot_data)

display(graph)

"""### **Support Vector Machine Model:**"""

scaler = RobustScaler()
X_scaled = scaler.fit_transform(X)

X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

svm_model = SVR(kernel='rbf', C=190000, gamma='scale')

svm_model.fit(X_train_scaled, y_train)

y_pred = svm_model.predict(X_test_scaled)

r2 = r2_score(y_test, y_pred)


accuracy_percent = r2 * 100
svm_score = accuracy_percent
print("Accuracy:", accuracy_percent)

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)

r2 = r2_score(y_test, y_pred)*100

svm_score = r2
svm_mae = mae

print(f"Mean Squared Error: {mse:.2f}")
print(f"Root Mean Squared Error: {rmse:.2f}")
print(f"Mean Absolute Error: {mae:.2f}")
print(" ")

train_accuracy = svm_model.score(X_train_scaled, y_train)
test_accuracy = svm_model.score(X_test_scaled, y_test)

print('Training accuracy:', train_accuracy)
print('Test accuracy:', test_accuracy)

plt.scatter(y_test, y_pred, color='green', alpha=0.2)

coefficients = np.polyfit(y_test, y_pred, 1)
polynomial = np.poly1d(coefficients)
plt.plot(y_test, polynomial(y_test), color='blue')

plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('SVM Regression: Actual vs Predicted Values')
plt.show()

"""### **Compare Models Accuracy:**

> Add blockquote


"""

models = ['Linear Regression','Decision Tree Regressor', 'SVM']
mae_scores = [linreg_mae, dectree_mae, svm_mae]
accuracy_scores = [linreg_score, dectree_score, svm_score]

sns.set(style="darkgrid")

fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))

sns.barplot(x=models, y=mae_scores, ax=axs[0])
axs[0].set_title('MAE Scores')
axs[0].set_ylabel('MAE')

for i, v in enumerate(mae_scores):
    axs[0].text(i, v, f"{v:.2f}", color='black', ha="center")


sns.barplot(x=models, y=accuracy_scores, ax=axs[1])
axs[1].set_title('Accuracy Scores')
axs[1].set_ylabel('Accuracy (%)')

for i, v in enumerate(accuracy_scores):
    axs[1].text(i, v, f"{v:.4f}", color='black', ha="center")

fig.tight_layout()
plt.show()

print(f'''The models prediction accuracy are as follows:

Linear Regression: {linreg_score:.4f}%
Decision Tree Regressor: {dectree_score:.4f}%
Support Machine Vector: {svm_score:.4f}%
''')
